{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rortiz/micromamba/envs/FTL8BS/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.17it/s]\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from textos import textoA98, textA11, textoA63, textoA8\n",
    "from textosXXL import textoA2\n",
    "from prompt import prompt1, prompt2\n",
    "\n",
    "# Cargar el modelo y el tokenizador\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "inputs_metadata = tokenizer(f'{prompt1}:{textoA98}', return_tensors=\"pt\")\n",
    "# Extraccion de los metadatos\n",
    "metadata_ids = model.generate(inputs_metadata['input_ids'], \n",
    "                             attention_mask=inputs_metadata['attention_mask'],\n",
    "                             pad_token_id=tokenizer.eos_token_id, \n",
    "                             max_new_tokens=150, \n",
    "                             min_new_tokens=60, \n",
    "                             length_penalty=2.0,\n",
    "                             num_beams=2)\n",
    "# Decodificar el resumen generado\n",
    "# metadata = tokenizer.decode(metadata_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "inputs_sintesis = tokenizer(f'{prompt2}:{textoA98}', return_tensors=\"pt\")\n",
    "# Generacion de la sintesis\n",
    "sintesis_ids = model.generate(inputs_sintesis['input_ids'], \n",
    "                             attention_mask=inputs_sintesis['attention_mask'],\n",
    "                             pad_token_id=tokenizer.eos_token_id, \n",
    "                             max_new_tokens=200, \n",
    "                             min_new_tokens=40, \n",
    "                             length_penalty=2.0, \n",
    "                             temperature=0.7,\n",
    "                             no_repeat_ngram_size=2,\n",
    "                             num_beams=4\n",
    "                             )\n",
    "# Decodificar el resumen generado\n",
    "# sintesis = tokenizer.decode(sintesis_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(metadata_ids[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28mlen\u001b[39m(inputs_metadata[\u001b[38;5;241m0\u001b[39m]):])))\n\u001b[1;32m      2\u001b[0m decoded_metadata \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(metadata_ids[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28mlen\u001b[39m(inputs_metadata[\u001b[38;5;241m0\u001b[39m]):], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(decoded_metadata)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(len(tokenizer.decode(metadata_ids[0][len(inputs_metadata[0]):])))\n",
    "decoded_metadata = tokenizer.decode(metadata_ids[0][len(inputs_metadata[0]):], skip_special_tokens=True)\n",
    "print(decoded_metadata)\n",
    "\n",
    "print(len(tokenizer.decode(sintesis_ids[0][len(inputs_sintesis[0]):])))\n",
    "decoded_sintesis = tokenizer.decode(sintesis_ids[0][len(inputs_sintesis[0]):], skip_special_tokens=True)\n",
    "print(decoded_sintesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_metadata = tokenizer(f'{prompt1}:{textoA98}', return_tensors=\"pt\").to(\"cuda\") \n",
    "# Extraccion de los metadatos\n",
    "metadata_ids = model.generate(inputs_metadata['input_ids'], \n",
    "                             attention_mask=inputs_metadata['attention_mask'],\n",
    "                             pad_token_id=tokenizer.eos_token_id, \n",
    "                             max_new_tokens=150, \n",
    "                             min_new_tokens=30, \n",
    "                             length_penalty=2.0,\n",
    "                             num_beams=2,\n",
    "                             )\n",
    "\n",
    "\n",
    "inputs_sintesis = tokenizer(f'{prompt2}:{textoA98}', return_tensors=\"pt\").to(\"cuda\") \n",
    "# Generacion de la sintesis\n",
    "sintesis_ids = model.generate(inputs_sintesis['input_ids'], \n",
    "                             attention_mask=inputs_sintesis['attention_mask'],\n",
    "                             pad_token_id=tokenizer.eos_token_id, \n",
    "                             max_new_tokens=200, \n",
    "                             min_new_tokens=40, \n",
    "                             length_penalty=2.0, \n",
    "                             temperature=0.7,\n",
    "                             no_repeat_ngram_size=2,\n",
    "                             num_beams=4\n",
    "                             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
